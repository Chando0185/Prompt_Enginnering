{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Few-Shot Learning and In-Context Learning Tutorial\n",
        "\n",
        "This tutorial explores the cutting-edge techniques of Few-Shot Learning and In-Context Learning using LLM's models and the LangChain library. These methods enable AI models to perform complex tasks with minimal examples, revolutionizing the way we approach machine learning problems."
      ],
      "metadata": {
        "id": "60ldBTVe8NQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method Details\n",
        "1. Basic Few-Shot Learning\n",
        "2. Advanced Few-Shot Techniques\n",
        "3. In-Context Learning\n"
      ],
      "metadata": {
        "id": "yxvmUc7m8Ye6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_core langchain_groq"
      ],
      "metadata": {
        "id": "kk8cQn1B8TDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key = \"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\",\n",
        "    model_name = \"llama-3.3-70b-versatile\"\n",
        ")"
      ],
      "metadata": {
        "id": "9jpoA9pB8uYS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Basic Few-Shot Learning"
      ],
      "metadata": {
        "id": "Ejxg6WnHjh9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_sentiment_classification(input_text):\n",
        "  few_shot_prompt = PromptTemplate(\n",
        "      input_variables=[\"input_text\"],\n",
        "      template=\"\"\"\n",
        "      Classify the sentiment as positive , negative , or neutral.\n",
        "\n",
        "      Example:\n",
        "      Text: I love this product! It's amazing.\n",
        "      Sentiment: Positive\n",
        "      Text: This movie was terriable. I hated it.\n",
        "      Sentiment: Negative\n",
        "      Text: The weather today is okay.\n",
        "      Sentiment: Neutral\n",
        "\n",
        "      Now, classify the following\n",
        "      Text: {input_text}\n",
        "      Sentiment:\n",
        "      \"\"\"\n",
        "  )\n",
        "  chain = few_shot_prompt | llm\n",
        "  result = chain.invoke(input_text).content\n",
        "  result = result.strip()\n",
        "\n",
        "  if ':' in result:\n",
        "    result = result.split(':')[1].strip()\n",
        "\n",
        "  return result\n",
        "\n",
        "test_text = \"I can't believe how great and spritual the kedarnath is!\"\n",
        "\n",
        "result = few_shot_sentiment_classification(test_text)\n",
        "print(f\"Text : {test_text}\")\n",
        "print(f\"Sentiment: {result}\")"
      ],
      "metadata": {
        "id": "pBvSNKOdHYwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023a3512-44e3-4957-e8d2-0a4c060ff856"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text : I can't believe how great and spritual the kedarnath is!\n",
            "Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Advanced Few-Shot Techniques"
      ],
      "metadata": {
        "id": "NxLobNAalgcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_task_few_shot(input_text, task):\n",
        "    few_shot_prompt = PromptTemplate(\n",
        "        input_variables=[\"input_text\", \"task\"],\n",
        "        template=\"\"\"\n",
        "        Perform the specified task on the given text.\n",
        "\n",
        "        Examples:\n",
        "        Text: I love this product! It's amazing.\n",
        "        Task: sentiment\n",
        "        Result: Positive\n",
        "\n",
        "        Text: This is the worst experience I've ever had.\n",
        "        Task: sentiment\n",
        "        Result: Negative\n",
        "\n",
        "        Text: Bonjour, comment allez-vous?\n",
        "        Task: language\n",
        "        Result: French\n",
        "\n",
        "        Text: Guten Tag, wie geht es Ihnen?\n",
        "        Task: language\n",
        "        Result: German\n",
        "\n",
        "        Text: কেমন আছেন? (Kemon achhen?)\n",
        "        Task: language\n",
        "        Result: Bangla\n",
        "\n",
        "        Text: The quick brown fox jumps over the lazy dog.\n",
        "        Task: count_words\n",
        "        Result: 9\n",
        "\n",
        "        Now, perform the following task:\n",
        "        Text: {input_text}\n",
        "        Task: {task}\n",
        "        Result:\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = few_shot_prompt | llm\n",
        "    return chain.invoke({\"input_text\": input_text, \"task\": task}).content\n",
        "\n",
        "print(multi_task_few_shot(\"I can't believe how great this is!\", \"sentiment\"))\n",
        "print(multi_task_few_shot(\"Guten Tag, wie geht es Ihnen?\", \"language\"))\n",
        "print(multi_task_few_shot(\"কেমন আছেন?\", \"language\"))\n",
        "print(multi_task_few_shot(\"The rain in Spain stays mainly in the plain.\", \"count_words\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMBFbi5klSLo",
        "outputId": "45798fda-d5a6-49d1-cd1a-1e4357817a90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: Positive\n",
            "Result: German\n",
            "Result: Bangla\n",
            "To perform the task, we need to count the words in the given text.\n",
            "\n",
            "The text is: \"The rain in Spain stays mainly in the plain.\"\n",
            "\n",
            "Here are the words:\n",
            "1. The\n",
            "2. rain\n",
            "3. in\n",
            "4. Spain\n",
            "5. stays\n",
            "6. mainly\n",
            "7. in\n",
            "8. the\n",
            "9. plain\n",
            "\n",
            "There are 9 words in the text.\n",
            "\n",
            "Result: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. In-Context Learning"
      ],
      "metadata": {
        "id": "zRu3T8KYmWFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def in_context_learning(task_description, examples, input_text):\n",
        "    example_text = \"\".join([f\"Input: {e['input']}\\nOutput: {e['output']}\\n\\n\" for e in examples])\n",
        "\n",
        "    in_context_prompt = PromptTemplate(\n",
        "        input_variables=[\"task_description\", \"examples\", \"input_text\"],\n",
        "        template=\"\"\"\n",
        "        Task: {task_description}\n",
        "\n",
        "        Examples:\n",
        "        {examples}\n",
        "\n",
        "        Now, perform the task on the following input:\n",
        "        Input: {input_text}\n",
        "        Output:\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = in_context_prompt | llm\n",
        "    return chain.invoke({\"task_description\": task_description, \"examples\": example_text, \"input_text\": input_text}).content\n",
        "\n",
        "task_desc = \"Convert the given text to pig latin.\"\n",
        "examples = [\n",
        "    {\"input\": \"hello\", \"output\": \"ellohay\"},\n",
        "    {\"input\": \"apple\", \"output\": \"appleay\"}\n",
        "]\n",
        "test_input = \"python\"\n",
        "\n",
        "result = in_context_learning(task_desc, examples, test_input)\n",
        "print(f\"Input: {test_input}\")\n",
        "print(f\"Output: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzDbk5OwmKh7",
        "outputId": "38f8b414-cdd4-4303-f9ca-91b045e66084"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: python\n",
            "Output: To convert the word \"python\" to Pig Latin, we need to move the first consonant (or consonant cluster) to the end of the word and add the sound \"ay\".\n",
            "\n",
            "So, \"python\" becomes \"ythonpay\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rvsz_dD6nE9r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}